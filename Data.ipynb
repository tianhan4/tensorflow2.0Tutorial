{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "In this notebook, we will go through several methods to load image data in Tensorflow for training, evaluation and prediction.\n",
    "The CIFAR-10 dataset (Canadian Institute For Advanced Research), one of the most widely used datasets for machine learning research is used, which is a collection of images that are commonly used to train machine learning and computer vision algorithms. The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class.\n",
    "![resources/cifar.PNG](resources/cifar.PNG)\n",
    "<sub>Source: https://www.cs.toronto.edu/~kriz/cifar.html</sub>\n",
    "\n",
    "tf.keras has provided built-in methods to downlaod and load several famous datasets, including CIFAR-10. We'll also try to use tf.data.Dataset for reading some raw images sampled from CIFAR-10. tf.data.Dataset is the best way to stream training data from disk. Datasets are iterables (not iterators), and work just like other Python iterables in Eager mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the class names of all classes in CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names_cifar10 = ['Airplane','Automobile','Bird','Cat','Deer',\n",
    "                       'Dog','Frog','Horse','Ship','Truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">The first method </font>: Use tensorflow.keras.datasets to load data with numpy format, which can be used directly in training/evaluation/prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "print(x_train.shape, ' ', y_train.shape)\n",
    "print(x_test.shape, ' ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "trainDataset = tf.data.Dataset.from_tensor_slices(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3)\n",
    "for i,image in enumerate(trainDataset):\n",
    "    if i>=6:\n",
    "        break\n",
    "    fig.subplots_adjust(hspace=0.6, wspace=0.4)\n",
    "    axes.flat[i].imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">The second method </font>: When you want to use some your own pictures to perform machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filenames = []\n",
    "for filename in os.listdir(\"./data\"):\n",
    "    if filename.endswith(\"jpg\") or filename.endswith(\"png\"):\n",
    "        filenames.append(os.path.join(\"./data\",filename))\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = tf.data.Dataset.from_tensor_slices(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in path_dataset:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(raw_image):\n",
    "    image_tensor = tf.image.decode_jpeg(raw_image)\n",
    "    image_tensor = tf.image.resize(image_tensor, [32, 32])\n",
    "    image_tensor /= 255.0\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = path_dataset.map(tf.io.read_file)\n",
    "image_dataset = raw_dataset.map(load_and_preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3)\n",
    "for i,image in enumerate(image_dataset):\n",
    "    fig.subplots_adjust(hspace=0.6, wspace=0.4)\n",
    "    axes.flat[i].imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">The third method </font>: We can also transform our image files into TFRecord files firstly, which are a simple format used for Tensorflow to pack multiple examples/images into the same file, TensorFlow is able to read multiple examples at once, which is especially important for performance when using a remote storage service such as GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrec = tf.data.experimental.TFRecordWriter('images.tfrec')\n",
    "tfrec.write(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = tf.data.TFRecordDataset('images.tfrec').map(load_and_preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3)\n",
    "for i,image in enumerate(image_dataset):\n",
    "    fig.subplots_adjust(hspace=0.6, wspace=0.4)\n",
    "    axes.flat[i].imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
